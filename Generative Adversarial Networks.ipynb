{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Activation, BatchNormalization, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " def discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "            Conv2D(64, (5, 5),\n",
    "            padding='same',\n",
    "            input_shape=(28,28,1))\n",
    "            )\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Conv2D(64, (5,5), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_with_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(np.sqrt(num))\n",
    "    height = int(np.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                    dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size):\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None]\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    d = discriminator()\n",
    "    g = generator()\n",
    "    d_with_g = generator_with_discriminator(g, d)\n",
    "    d_opt = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_opt = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "    d_with_g.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "    for epoch in range(100):\n",
    "        print(\"Epoch #: \", epoch)\n",
    "        print('Number of batches', int(X_train.shape[0]/batch_size))\n",
    "        for index in range(int(X_train.shape[0]/batch_size)):\n",
    "            noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            image_batch = X_train[index*batch_size: (index+1)*batch_size]\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5 + 127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * batch_size + [0] * batch_size\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch: {}   d_loss:  {}\".format(index, d_loss))\n",
    "            noise = np.random.uniform(-1, 1, (batch_size, 100))\n",
    "            d.trainable = False\n",
    "            g_loss = d_with_g.train_on_batch(noise, [1] * batch_size)\n",
    "            d.trainable = True\n",
    "            print(\"batch: {}   g_loss:  {}\".format(index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(batch_size, nice=False):\n",
    "    g = generator()\n",
    "    g.compile(loss='categorical_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator()\n",
    "        d.compile(loss='categorical_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (batch_size*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, batch_size*20)\n",
    "        index.resize((batch_size*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((batch_size,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(batch_size):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (batch_size, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5 + 127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save('generated_image.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tb\n",
    "# def get_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--mode\", type=str)\n",
    "#     parser.add_argument(\"--batch-size\", type=int, default=128)\n",
    "#     parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
    "#     parser.set_defaults(nice=False)\n",
    "#     args = parser.parse_args()\n",
    "#     return args\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     args = get_args()\n",
    "#     if args.mode == \"train\":\n",
    "#         train(batch_size=args.batch_size)\n",
    "#     elif args.mode == \"generate\":\n",
    "#         generate(batch_size=args.batch_size, nice=args.nice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1024, input_dim=100)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #:  0\n",
      "Number of batches 468\n",
      "batch: 0   d_loss:  0.6886478662490845\n",
      "batch: 0   g_loss:  0.6501742005348206\n",
      "batch: 1   d_loss:  0.6802733540534973\n",
      "batch: 1   g_loss:  0.6471580266952515\n",
      "batch: 2   d_loss:  0.6713612079620361\n",
      "batch: 2   g_loss:  0.6437466740608215\n",
      "batch: 3   d_loss:  0.6571463942527771\n",
      "batch: 3   g_loss:  0.6368536949157715\n",
      "batch: 4   d_loss:  0.6450299620628357\n",
      "batch: 4   g_loss:  0.6298059225082397\n",
      "batch: 5   d_loss:  0.6255583167076111\n",
      "batch: 5   g_loss:  0.6248408555984497\n",
      "batch: 6   d_loss:  0.6073341369628906\n",
      "batch: 6   g_loss:  0.6195707321166992\n",
      "batch: 7   d_loss:  0.5945340394973755\n",
      "batch: 7   g_loss:  0.6154245138168335\n",
      "batch: 8   d_loss:  0.575135350227356\n",
      "batch: 8   g_loss:  0.6065338850021362\n",
      "batch: 9   d_loss:  0.559829831123352\n",
      "batch: 9   g_loss:  0.5981008410453796\n",
      "batch: 10   d_loss:  0.5420458316802979\n",
      "batch: 10   g_loss:  0.5896244049072266\n",
      "batch: 11   d_loss:  0.5307350754737854\n",
      "batch: 11   g_loss:  0.5790247321128845\n",
      "batch: 12   d_loss:  0.5144009590148926\n",
      "batch: 12   g_loss:  0.5727494955062866\n",
      "batch: 13   d_loss:  0.5007656216621399\n",
      "batch: 13   g_loss:  0.5666189193725586\n",
      "batch: 14   d_loss:  0.48871153593063354\n",
      "batch: 14   g_loss:  0.5579499006271362\n",
      "batch: 15   d_loss:  0.4785311818122864\n",
      "batch: 15   g_loss:  0.5520790219306946\n",
      "batch: 16   d_loss:  0.46850016713142395\n",
      "batch: 16   g_loss:  0.5468241572380066\n",
      "batch: 17   d_loss:  0.4601373076438904\n",
      "batch: 17   g_loss:  0.5409942269325256\n",
      "batch: 18   d_loss:  0.4496809244155884\n",
      "batch: 18   g_loss:  0.5412882566452026\n",
      "batch: 19   d_loss:  0.44089335203170776\n",
      "batch: 19   g_loss:  0.5391247272491455\n",
      "batch: 20   d_loss:  0.43333303928375244\n",
      "batch: 20   g_loss:  0.5446221828460693\n",
      "batch: 21   d_loss:  0.4276931881904602\n",
      "batch: 21   g_loss:  0.5525988936424255\n",
      "batch: 22   d_loss:  0.4203132092952728\n",
      "batch: 22   g_loss:  0.5609661936759949\n",
      "batch: 23   d_loss:  0.41257405281066895\n",
      "batch: 23   g_loss:  0.5842124223709106\n",
      "batch: 24   d_loss:  0.40523824095726013\n",
      "batch: 24   g_loss:  0.6060973405838013\n",
      "batch: 25   d_loss:  0.3980353772640228\n",
      "batch: 25   g_loss:  0.6349617838859558\n",
      "batch: 26   d_loss:  0.3930506110191345\n",
      "batch: 26   g_loss:  0.6740353107452393\n",
      "batch: 27   d_loss:  0.3869512677192688\n",
      "batch: 27   g_loss:  0.7215605974197388\n",
      "batch: 28   d_loss:  0.3839096426963806\n",
      "batch: 28   g_loss:  0.7701245546340942\n",
      "batch: 29   d_loss:  0.3761206865310669\n",
      "batch: 29   g_loss:  0.831192135810852\n",
      "batch: 30   d_loss:  0.36908578872680664\n",
      "batch: 30   g_loss:  0.8862420916557312\n",
      "batch: 31   d_loss:  0.3646048307418823\n",
      "batch: 31   g_loss:  0.9460840225219727\n",
      "batch: 32   d_loss:  0.358984112739563\n",
      "batch: 32   g_loss:  1.0017023086547852\n",
      "batch: 33   d_loss:  0.3552219867706299\n",
      "batch: 33   g_loss:  1.0399821996688843\n",
      "batch: 34   d_loss:  0.35183751583099365\n",
      "batch: 34   g_loss:  1.0559337139129639\n",
      "batch: 35   d_loss:  0.35136497020721436\n",
      "batch: 35   g_loss:  1.048626184463501\n",
      "batch: 36   d_loss:  0.3516629636287689\n",
      "batch: 36   g_loss:  1.0107470750808716\n",
      "batch: 37   d_loss:  0.35229864716529846\n",
      "batch: 37   g_loss:  0.9474000334739685\n",
      "batch: 38   d_loss:  0.3524727523326874\n",
      "batch: 38   g_loss:  0.8714083433151245\n",
      "batch: 39   d_loss:  0.3545864522457123\n",
      "batch: 39   g_loss:  0.8000379204750061\n",
      "batch: 40   d_loss:  0.3586735725402832\n",
      "batch: 40   g_loss:  0.7400370240211487\n",
      "batch: 41   d_loss:  0.3618071377277374\n",
      "batch: 41   g_loss:  0.7126255035400391\n",
      "batch: 42   d_loss:  0.36178943514823914\n",
      "batch: 42   g_loss:  0.7044683694839478\n",
      "batch: 43   d_loss:  0.36074182391166687\n",
      "batch: 43   g_loss:  0.7035737037658691\n",
      "batch: 44   d_loss:  0.3592352867126465\n",
      "batch: 44   g_loss:  0.7073157429695129\n",
      "batch: 45   d_loss:  0.35580354928970337\n",
      "batch: 45   g_loss:  0.7113566994667053\n",
      "batch: 46   d_loss:  0.3554524779319763\n",
      "batch: 46   g_loss:  0.7148239612579346\n",
      "batch: 47   d_loss:  0.3549759089946747\n",
      "batch: 47   g_loss:  0.7182232737541199\n",
      "batch: 48   d_loss:  0.3509456515312195\n",
      "batch: 48   g_loss:  0.7218502759933472\n",
      "batch: 49   d_loss:  0.34842848777770996\n",
      "batch: 49   g_loss:  0.7255406379699707\n",
      "batch: 50   d_loss:  0.34636884927749634\n",
      "batch: 50   g_loss:  0.7284413576126099\n",
      "batch: 51   d_loss:  0.3440898060798645\n",
      "batch: 51   g_loss:  0.7309325933456421\n",
      "batch: 52   d_loss:  0.3415501117706299\n",
      "batch: 52   g_loss:  0.7334110736846924\n",
      "batch: 53   d_loss:  0.34098440408706665\n",
      "batch: 53   g_loss:  0.735267162322998\n",
      "batch: 54   d_loss:  0.3407401442527771\n",
      "batch: 54   g_loss:  0.7371585369110107\n",
      "batch: 55   d_loss:  0.33820009231567383\n",
      "batch: 55   g_loss:  0.7390671968460083\n",
      "batch: 56   d_loss:  0.3371417820453644\n",
      "batch: 56   g_loss:  0.7408778667449951\n",
      "batch: 57   d_loss:  0.3351518511772156\n",
      "batch: 57   g_loss:  0.7426437139511108\n",
      "batch: 58   d_loss:  0.3343851566314697\n",
      "batch: 58   g_loss:  0.744499146938324\n",
      "batch: 59   d_loss:  0.3341294527053833\n",
      "batch: 59   g_loss:  0.7463624477386475\n",
      "batch: 60   d_loss:  0.3328954875469208\n",
      "batch: 60   g_loss:  0.7482413053512573\n",
      "batch: 61   d_loss:  0.33328741788864136\n",
      "batch: 61   g_loss:  0.7499940991401672\n",
      "batch: 62   d_loss:  0.33229053020477295\n",
      "batch: 62   g_loss:  0.7518472671508789\n",
      "batch: 63   d_loss:  0.3295317590236664\n",
      "batch: 63   g_loss:  0.753706693649292\n",
      "batch: 64   d_loss:  0.3287459909915924\n",
      "batch: 64   g_loss:  0.7556066513061523\n",
      "batch: 65   d_loss:  0.32776182889938354\n",
      "batch: 65   g_loss:  0.7574570178985596\n",
      "batch: 66   d_loss:  0.32858729362487793\n",
      "batch: 66   g_loss:  0.759266197681427\n",
      "batch: 67   d_loss:  0.3269153833389282\n",
      "batch: 67   g_loss:  0.7610920667648315\n",
      "batch: 68   d_loss:  0.3246711492538452\n",
      "batch: 68   g_loss:  0.7630380392074585\n",
      "batch: 69   d_loss:  0.3234999179840088\n",
      "batch: 69   g_loss:  0.7648719549179077\n",
      "batch: 70   d_loss:  0.32277774810791016\n",
      "batch: 70   g_loss:  0.7668307423591614\n",
      "batch: 71   d_loss:  0.3211144208908081\n",
      "batch: 71   g_loss:  0.7687762379646301\n",
      "batch: 72   d_loss:  0.3201499581336975\n",
      "batch: 72   g_loss:  0.7707698345184326\n",
      "batch: 73   d_loss:  0.32010531425476074\n",
      "batch: 73   g_loss:  0.7727813720703125\n",
      "batch: 74   d_loss:  0.3187157213687897\n",
      "batch: 74   g_loss:  0.7748366594314575\n",
      "batch: 75   d_loss:  0.3178313672542572\n",
      "batch: 75   g_loss:  0.776849627494812\n",
      "batch: 76   d_loss:  0.31634634733200073\n",
      "batch: 76   g_loss:  0.7789026498794556\n",
      "batch: 77   d_loss:  0.31524091958999634\n",
      "batch: 77   g_loss:  0.7810072898864746\n",
      "batch: 78   d_loss:  0.31443557143211365\n",
      "batch: 78   g_loss:  0.7830743789672852\n",
      "batch: 79   d_loss:  0.31412559747695923\n",
      "batch: 79   g_loss:  0.7851906418800354\n",
      "batch: 80   d_loss:  0.313944935798645\n",
      "batch: 80   g_loss:  0.787340521812439\n",
      "batch: 81   d_loss:  0.31187552213668823\n",
      "batch: 81   g_loss:  0.789497435092926\n",
      "batch: 82   d_loss:  0.3105029761791229\n",
      "batch: 82   g_loss:  0.7917054295539856\n",
      "batch: 83   d_loss:  0.30879735946655273\n",
      "batch: 83   g_loss:  0.7939029932022095\n",
      "batch: 84   d_loss:  0.30828794836997986\n",
      "batch: 84   g_loss:  0.7961246967315674\n",
      "batch: 85   d_loss:  0.3073171079158783\n",
      "batch: 85   g_loss:  0.7983950972557068\n",
      "batch: 86   d_loss:  0.3065878748893738\n",
      "batch: 86   g_loss:  0.800746500492096\n",
      "batch: 87   d_loss:  0.30506518483161926\n",
      "batch: 87   g_loss:  0.8030694723129272\n",
      "batch: 88   d_loss:  0.3039219379425049\n",
      "batch: 88   g_loss:  0.8054292798042297\n",
      "batch: 89   d_loss:  0.3025658428668976\n",
      "batch: 89   g_loss:  0.8078455924987793\n",
      "batch: 90   d_loss:  0.3016025722026825\n",
      "batch: 90   g_loss:  0.8102564811706543\n",
      "batch: 91   d_loss:  0.3004174530506134\n",
      "batch: 91   g_loss:  0.8127864599227905\n",
      "batch: 92   d_loss:  0.29927584528923035\n",
      "batch: 92   g_loss:  0.8152837753295898\n",
      "batch: 93   d_loss:  0.29852089285850525\n",
      "batch: 93   g_loss:  0.8177995681762695\n",
      "batch: 94   d_loss:  0.2974485158920288\n",
      "batch: 94   g_loss:  0.8203631043434143\n",
      "batch: 95   d_loss:  0.29672327637672424\n",
      "batch: 95   g_loss:  0.8229962587356567\n",
      "batch: 96   d_loss:  0.2955312430858612\n",
      "batch: 96   g_loss:  0.8256822824478149\n",
      "batch: 97   d_loss:  0.29461580514907837\n",
      "batch: 97   g_loss:  0.8283636569976807\n",
      "batch: 98   d_loss:  0.29352444410324097\n",
      "batch: 98   g_loss:  0.8310773968696594\n",
      "batch: 99   d_loss:  0.291939377784729\n",
      "batch: 99   g_loss:  0.8338930606842041\n",
      "batch: 100   d_loss:  0.29053446650505066\n",
      "batch: 100   g_loss:  0.8367070555686951\n",
      "batch: 101   d_loss:  0.2901366353034973\n",
      "batch: 101   g_loss:  0.8395872712135315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 102   d_loss:  0.28903061151504517\n",
      "batch: 102   g_loss:  0.8425058722496033\n",
      "batch: 103   d_loss:  0.2878354489803314\n",
      "batch: 103   g_loss:  0.8454259037971497\n",
      "batch: 104   d_loss:  0.28622734546661377\n",
      "batch: 104   g_loss:  0.8484641909599304\n",
      "batch: 105   d_loss:  0.285605251789093\n",
      "batch: 105   g_loss:  0.8515022397041321\n",
      "batch: 106   d_loss:  0.2837252616882324\n",
      "batch: 106   g_loss:  0.8545708060264587\n",
      "batch: 107   d_loss:  0.2819242775440216\n",
      "batch: 107   g_loss:  0.8577473163604736\n",
      "batch: 108   d_loss:  0.28126776218414307\n",
      "batch: 108   g_loss:  0.8609595894813538\n",
      "batch: 109   d_loss:  0.28037068247795105\n",
      "batch: 109   g_loss:  0.864219605922699\n",
      "batch: 110   d_loss:  0.2799861431121826\n",
      "batch: 110   g_loss:  0.867525041103363\n",
      "batch: 111   d_loss:  0.27821582555770874\n",
      "batch: 111   g_loss:  0.870856523513794\n",
      "batch: 112   d_loss:  0.2762184739112854\n",
      "batch: 112   g_loss:  0.87428879737854\n",
      "batch: 113   d_loss:  0.274557888507843\n",
      "batch: 113   g_loss:  0.8777478933334351\n",
      "batch: 114   d_loss:  0.2741159200668335\n",
      "batch: 114   g_loss:  0.8813288807868958\n",
      "batch: 115   d_loss:  0.2727586328983307\n",
      "batch: 115   g_loss:  0.8849325180053711\n",
      "batch: 116   d_loss:  0.27091947197914124\n",
      "batch: 116   g_loss:  0.8885343074798584\n",
      "batch: 117   d_loss:  0.26929616928100586\n",
      "batch: 117   g_loss:  0.8923389911651611\n",
      "batch: 118   d_loss:  0.2679831385612488\n",
      "batch: 118   g_loss:  0.8961167335510254\n",
      "batch: 119   d_loss:  0.2664830684661865\n",
      "batch: 119   g_loss:  0.8999298810958862\n",
      "batch: 120   d_loss:  0.2651161253452301\n",
      "batch: 120   g_loss:  0.9038498997688293\n",
      "batch: 121   d_loss:  0.26409226655960083\n",
      "batch: 121   g_loss:  0.907903790473938\n",
      "batch: 122   d_loss:  0.2626951336860657\n",
      "batch: 122   g_loss:  0.9119403958320618\n",
      "batch: 123   d_loss:  0.2612176537513733\n",
      "batch: 123   g_loss:  0.9160925149917603\n",
      "batch: 124   d_loss:  0.2598477900028229\n",
      "batch: 124   g_loss:  0.9202936887741089\n",
      "batch: 125   d_loss:  0.25863587856292725\n",
      "batch: 125   g_loss:  0.9245564937591553\n",
      "batch: 126   d_loss:  0.2572612464427948\n",
      "batch: 126   g_loss:  0.9289223551750183\n",
      "batch: 127   d_loss:  0.2555461525917053\n",
      "batch: 127   g_loss:  0.9333048462867737\n",
      "batch: 128   d_loss:  0.2538224160671234\n",
      "batch: 128   g_loss:  0.9378542304039001\n",
      "batch: 129   d_loss:  0.25249040126800537\n",
      "batch: 129   g_loss:  0.9424842000007629\n",
      "batch: 130   d_loss:  0.2508581280708313\n",
      "batch: 130   g_loss:  0.9470985531806946\n",
      "batch: 131   d_loss:  0.24943751096725464\n",
      "batch: 131   g_loss:  0.9518765211105347\n",
      "batch: 132   d_loss:  0.24796339869499207\n",
      "batch: 132   g_loss:  0.9567426443099976\n",
      "batch: 133   d_loss:  0.24645797908306122\n",
      "batch: 133   g_loss:  0.9616519212722778\n",
      "batch: 134   d_loss:  0.2451547235250473\n",
      "batch: 134   g_loss:  0.9666979312896729\n",
      "batch: 135   d_loss:  0.24351553618907928\n",
      "batch: 135   g_loss:  0.9718190431594849\n",
      "batch: 136   d_loss:  0.24159371852874756\n",
      "batch: 136   g_loss:  0.9770365357398987\n",
      "batch: 137   d_loss:  0.23977380990982056\n",
      "batch: 137   g_loss:  0.9823050498962402\n",
      "batch: 138   d_loss:  0.23813965916633606\n",
      "batch: 138   g_loss:  0.9877045750617981\n",
      "batch: 139   d_loss:  0.23646651208400726\n",
      "batch: 139   g_loss:  0.9931771755218506\n",
      "batch: 140   d_loss:  0.23509418964385986\n",
      "batch: 140   g_loss:  0.9987517595291138\n",
      "batch: 141   d_loss:  0.23328135907649994\n",
      "batch: 141   g_loss:  1.0043981075286865\n",
      "batch: 142   d_loss:  0.23191606998443604\n",
      "batch: 142   g_loss:  1.010224461555481\n",
      "batch: 143   d_loss:  0.22981759905815125\n",
      "batch: 143   g_loss:  1.0161141157150269\n",
      "batch: 144   d_loss:  0.22828051447868347\n",
      "batch: 144   g_loss:  1.0220682621002197\n",
      "batch: 145   d_loss:  0.22687876224517822\n",
      "batch: 145   g_loss:  1.0281091928482056\n",
      "batch: 146   d_loss:  0.22495172917842865\n",
      "batch: 146   g_loss:  1.0343167781829834\n",
      "batch: 147   d_loss:  0.223175510764122\n",
      "batch: 147   g_loss:  1.0406208038330078\n",
      "batch: 148   d_loss:  0.2212371528148651\n",
      "batch: 148   g_loss:  1.0469589233398438\n",
      "batch: 149   d_loss:  0.21944090723991394\n",
      "batch: 149   g_loss:  1.053518533706665\n",
      "batch: 150   d_loss:  0.21864210069179535\n",
      "batch: 150   g_loss:  1.0600879192352295\n",
      "batch: 151   d_loss:  0.21705292165279388\n",
      "batch: 151   g_loss:  1.0667668581008911\n",
      "batch: 152   d_loss:  0.2151309698820114\n",
      "batch: 152   g_loss:  1.0737030506134033\n",
      "batch: 153   d_loss:  0.21300283074378967\n",
      "batch: 153   g_loss:  1.0806002616882324\n",
      "batch: 154   d_loss:  0.21149973571300507\n",
      "batch: 154   g_loss:  1.0875868797302246\n",
      "batch: 155   d_loss:  0.2099379003047943\n",
      "batch: 155   g_loss:  1.094842791557312\n",
      "batch: 156   d_loss:  0.20808029174804688\n",
      "batch: 156   g_loss:  1.1020820140838623\n",
      "batch: 157   d_loss:  0.20572230219841003\n",
      "batch: 157   g_loss:  1.1095349788665771\n",
      "batch: 158   d_loss:  0.2033592015504837\n",
      "batch: 158   g_loss:  1.1170649528503418\n",
      "batch: 159   d_loss:  0.2015971839427948\n",
      "batch: 159   g_loss:  1.1246713399887085\n",
      "batch: 160   d_loss:  0.19983601570129395\n",
      "batch: 160   g_loss:  1.1323802471160889\n",
      "batch: 161   d_loss:  0.19806763529777527\n",
      "batch: 161   g_loss:  1.1403254270553589\n",
      "batch: 162   d_loss:  0.1958637535572052\n",
      "batch: 162   g_loss:  1.1483659744262695\n",
      "batch: 163   d_loss:  0.1943192183971405\n",
      "batch: 163   g_loss:  1.1564323902130127\n",
      "batch: 164   d_loss:  0.19195231795310974\n",
      "batch: 164   g_loss:  1.1647326946258545\n",
      "batch: 165   d_loss:  0.1903325319290161\n",
      "batch: 165   g_loss:  1.173078179359436\n",
      "batch: 166   d_loss:  0.18873269855976105\n",
      "batch: 166   g_loss:  1.181614637374878\n",
      "batch: 167   d_loss:  0.18714071810245514\n",
      "batch: 167   g_loss:  1.190099835395813\n",
      "batch: 168   d_loss:  0.18472427129745483\n",
      "batch: 168   g_loss:  1.1988698244094849\n",
      "batch: 169   d_loss:  0.18222127854824066\n",
      "batch: 169   g_loss:  1.2078166007995605\n",
      "batch: 170   d_loss:  0.1815449297428131\n",
      "batch: 170   g_loss:  1.2167805433273315\n",
      "batch: 171   d_loss:  0.1796836107969284\n",
      "batch: 171   g_loss:  1.225874423980713\n",
      "batch: 172   d_loss:  0.1771816909313202\n",
      "batch: 172   g_loss:  1.2349910736083984\n",
      "batch: 173   d_loss:  0.1752324402332306\n",
      "batch: 173   g_loss:  1.244360089302063\n",
      "batch: 174   d_loss:  0.17296788096427917\n",
      "batch: 174   g_loss:  1.2538628578186035\n",
      "batch: 175   d_loss:  0.1711132526397705\n",
      "batch: 175   g_loss:  1.2633453607559204\n",
      "batch: 176   d_loss:  0.1694456934928894\n",
      "batch: 176   g_loss:  1.2731084823608398\n",
      "batch: 177   d_loss:  0.168244868516922\n",
      "batch: 177   g_loss:  1.2829620838165283\n",
      "batch: 178   d_loss:  0.1658822000026703\n",
      "batch: 178   g_loss:  1.2928650379180908\n",
      "batch: 179   d_loss:  0.1641736775636673\n",
      "batch: 179   g_loss:  1.3029149770736694\n",
      "batch: 180   d_loss:  0.16232746839523315\n",
      "batch: 180   g_loss:  1.313108205795288\n",
      "batch: 181   d_loss:  0.15986424684524536\n",
      "batch: 181   g_loss:  1.3234610557556152\n",
      "batch: 182   d_loss:  0.1583312302827835\n",
      "batch: 182   g_loss:  1.3338290452957153\n",
      "batch: 183   d_loss:  0.1559736281633377\n",
      "batch: 183   g_loss:  1.3443551063537598\n",
      "batch: 184   d_loss:  0.15371400117874146\n",
      "batch: 184   g_loss:  1.355051040649414\n",
      "batch: 185   d_loss:  0.15209133923053741\n",
      "batch: 185   g_loss:  1.3657602071762085\n",
      "batch: 186   d_loss:  0.1503499448299408\n",
      "batch: 186   g_loss:  1.3767095804214478\n",
      "batch: 187   d_loss:  0.1483256220817566\n",
      "batch: 187   g_loss:  1.3876960277557373\n",
      "batch: 188   d_loss:  0.14643381536006927\n",
      "batch: 188   g_loss:  1.3988356590270996\n",
      "batch: 189   d_loss:  0.14462563395500183\n",
      "batch: 189   g_loss:  1.4100639820098877\n",
      "batch: 190   d_loss:  0.14294257760047913\n",
      "batch: 190   g_loss:  1.4213650226593018\n",
      "batch: 191   d_loss:  0.14118623733520508\n",
      "batch: 191   g_loss:  1.4327373504638672\n",
      "batch: 192   d_loss:  0.13942524790763855\n",
      "batch: 192   g_loss:  1.444364309310913\n",
      "batch: 193   d_loss:  0.13722294569015503\n",
      "batch: 193   g_loss:  1.456005573272705\n",
      "batch: 194   d_loss:  0.13511040806770325\n",
      "batch: 194   g_loss:  1.467777967453003\n",
      "batch: 195   d_loss:  0.1336948126554489\n",
      "batch: 195   g_loss:  1.4795172214508057\n",
      "batch: 196   d_loss:  0.13190017640590668\n",
      "batch: 196   g_loss:  1.4915412664413452\n",
      "batch: 197   d_loss:  0.1317785382270813\n",
      "batch: 197   g_loss:  1.503499984741211\n",
      "batch: 198   d_loss:  0.12943455576896667\n",
      "batch: 198   g_loss:  1.5155696868896484\n",
      "batch: 199   d_loss:  0.12690898776054382\n",
      "batch: 199   g_loss:  1.5277910232543945\n",
      "batch: 200   d_loss:  0.12524357438087463\n",
      "batch: 200   g_loss:  1.5399330854415894\n",
      "batch: 201   d_loss:  0.12306904792785645\n",
      "batch: 201   g_loss:  1.5523207187652588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 202   d_loss:  0.12120196223258972\n",
      "batch: 202   g_loss:  1.5647674798965454\n",
      "batch: 203   d_loss:  0.12038439512252808\n",
      "batch: 203   g_loss:  1.5773017406463623\n",
      "batch: 204   d_loss:  0.11833310127258301\n",
      "batch: 204   g_loss:  1.5897983312606812\n",
      "batch: 205   d_loss:  0.11654660850763321\n",
      "batch: 205   g_loss:  1.6024954319000244\n",
      "batch: 206   d_loss:  0.11498434841632843\n",
      "batch: 206   g_loss:  1.6151649951934814\n",
      "batch: 207   d_loss:  0.11319732666015625\n",
      "batch: 207   g_loss:  1.62790846824646\n",
      "batch: 208   d_loss:  0.11198340356349945\n",
      "batch: 208   g_loss:  1.6407408714294434\n",
      "batch: 209   d_loss:  0.1106451228260994\n",
      "batch: 209   g_loss:  1.6537134647369385\n",
      "batch: 210   d_loss:  0.10860374569892883\n",
      "batch: 210   g_loss:  1.6666924953460693\n",
      "batch: 211   d_loss:  0.1077309399843216\n",
      "batch: 211   g_loss:  1.67973792552948\n",
      "batch: 212   d_loss:  0.1065448671579361\n",
      "batch: 212   g_loss:  1.692825198173523\n",
      "batch: 213   d_loss:  0.1048436239361763\n",
      "batch: 213   g_loss:  1.7059223651885986\n",
      "batch: 214   d_loss:  0.10311689227819443\n",
      "batch: 214   g_loss:  1.7191296815872192\n",
      "batch: 215   d_loss:  0.10126663744449615\n",
      "batch: 215   g_loss:  1.7323472499847412\n",
      "batch: 216   d_loss:  0.09951753914356232\n",
      "batch: 216   g_loss:  1.745600700378418\n",
      "batch: 217   d_loss:  0.09823627769947052\n",
      "batch: 217   g_loss:  1.7587980031967163\n",
      "batch: 218   d_loss:  0.0974569320678711\n",
      "batch: 218   g_loss:  1.7722959518432617\n",
      "batch: 219   d_loss:  0.09630805999040604\n",
      "batch: 219   g_loss:  1.7856957912445068\n",
      "batch: 220   d_loss:  0.09516124427318573\n",
      "batch: 220   g_loss:  1.7991089820861816\n",
      "batch: 221   d_loss:  0.0937398299574852\n",
      "batch: 221   g_loss:  1.8125030994415283\n",
      "batch: 222   d_loss:  0.09220589697360992\n",
      "batch: 222   g_loss:  1.8259612321853638\n",
      "batch: 223   d_loss:  0.09082993119955063\n",
      "batch: 223   g_loss:  1.8394293785095215\n",
      "batch: 224   d_loss:  0.08903159946203232\n",
      "batch: 224   g_loss:  1.852952241897583\n",
      "batch: 225   d_loss:  0.08821374177932739\n",
      "batch: 225   g_loss:  1.8664329051971436\n",
      "batch: 226   d_loss:  0.08689522743225098\n",
      "batch: 226   g_loss:  1.8800212144851685\n",
      "batch: 227   d_loss:  0.08490167558193207\n",
      "batch: 227   g_loss:  1.8934977054595947\n",
      "batch: 228   d_loss:  0.08438902348279953\n",
      "batch: 228   g_loss:  1.907109022140503\n",
      "batch: 229   d_loss:  0.08382747322320938\n",
      "batch: 229   g_loss:  1.9206297397613525\n",
      "batch: 230   d_loss:  0.08189531415700912\n",
      "batch: 230   g_loss:  1.9342390298843384\n",
      "batch: 231   d_loss:  0.08023902028799057\n",
      "batch: 231   g_loss:  1.9477448463439941\n",
      "batch: 232   d_loss:  0.07892762124538422\n",
      "batch: 232   g_loss:  1.9613460302352905\n",
      "batch: 233   d_loss:  0.07806932926177979\n",
      "batch: 233   g_loss:  1.9748609066009521\n",
      "batch: 234   d_loss:  0.07690660655498505\n",
      "batch: 234   g_loss:  1.988442301750183\n",
      "batch: 235   d_loss:  0.07604574412107468\n",
      "batch: 235   g_loss:  2.001948356628418\n",
      "batch: 236   d_loss:  0.07489034533500671\n",
      "batch: 236   g_loss:  2.015482187271118\n",
      "batch: 237   d_loss:  0.07425369322299957\n",
      "batch: 237   g_loss:  2.028994083404541\n",
      "batch: 238   d_loss:  0.07290945947170258\n",
      "batch: 238   g_loss:  2.0425286293029785\n",
      "batch: 239   d_loss:  0.07121191173791885\n",
      "batch: 239   g_loss:  2.055960178375244\n",
      "batch: 240   d_loss:  0.07060512900352478\n",
      "batch: 240   g_loss:  2.06950044631958\n",
      "batch: 241   d_loss:  0.06962116062641144\n",
      "batch: 241   g_loss:  2.0829238891601562\n",
      "batch: 242   d_loss:  0.06887902319431305\n",
      "batch: 242   g_loss:  2.096403121948242\n",
      "batch: 243   d_loss:  0.06796561181545258\n",
      "batch: 243   g_loss:  2.1098127365112305\n",
      "batch: 244   d_loss:  0.0667601153254509\n",
      "batch: 244   g_loss:  2.1232941150665283\n",
      "batch: 245   d_loss:  0.06600737571716309\n",
      "batch: 245   g_loss:  2.1366500854492188\n",
      "batch: 246   d_loss:  0.06473466008901596\n",
      "batch: 246   g_loss:  2.1499953269958496\n",
      "batch: 247   d_loss:  0.06408889591693878\n",
      "batch: 247   g_loss:  2.163346767425537\n",
      "batch: 248   d_loss:  0.06323857605457306\n",
      "batch: 248   g_loss:  2.1767144203186035\n",
      "batch: 249   d_loss:  0.062392447143793106\n",
      "batch: 249   g_loss:  2.189988374710083\n",
      "batch: 250   d_loss:  0.06175709515810013\n",
      "batch: 250   g_loss:  2.203214645385742\n",
      "batch: 251   d_loss:  0.06080204248428345\n",
      "batch: 251   g_loss:  2.2164251804351807\n",
      "batch: 252   d_loss:  0.06032487750053406\n",
      "batch: 252   g_loss:  2.2296226024627686\n",
      "batch: 253   d_loss:  0.05999009683728218\n",
      "batch: 253   g_loss:  2.24277925491333\n",
      "batch: 254   d_loss:  0.05839371681213379\n",
      "batch: 254   g_loss:  2.2558650970458984\n",
      "batch: 255   d_loss:  0.05730023235082626\n",
      "batch: 255   g_loss:  2.268944263458252\n",
      "batch: 256   d_loss:  0.056663841009140015\n",
      "batch: 256   g_loss:  2.281947612762451\n",
      "batch: 257   d_loss:  0.05631354823708534\n",
      "batch: 257   g_loss:  2.2950243949890137\n",
      "batch: 258   d_loss:  0.05563025176525116\n",
      "batch: 258   g_loss:  2.3079586029052734\n",
      "batch: 259   d_loss:  0.05473259836435318\n",
      "batch: 259   g_loss:  2.3208200931549072\n",
      "batch: 260   d_loss:  0.053945187479257584\n",
      "batch: 260   g_loss:  2.333686351776123\n",
      "batch: 261   d_loss:  0.05304412171244621\n",
      "batch: 261   g_loss:  2.3465638160705566\n",
      "batch: 262   d_loss:  0.052056267857551575\n",
      "batch: 262   g_loss:  2.3593692779541016\n",
      "batch: 263   d_loss:  0.05159224569797516\n",
      "batch: 263   g_loss:  2.3720805644989014\n",
      "batch: 264   d_loss:  0.051254868507385254\n",
      "batch: 264   g_loss:  2.384742021560669\n",
      "batch: 265   d_loss:  0.050294019281864166\n",
      "batch: 265   g_loss:  2.3974077701568604\n",
      "batch: 266   d_loss:  0.04980124905705452\n",
      "batch: 266   g_loss:  2.4100279808044434\n",
      "batch: 267   d_loss:  0.049008890986442566\n",
      "batch: 267   g_loss:  2.422584295272827\n",
      "batch: 268   d_loss:  0.048898033797740936\n",
      "batch: 268   g_loss:  2.4350404739379883\n",
      "batch: 269   d_loss:  0.04822733998298645\n",
      "batch: 269   g_loss:  2.4474658966064453\n",
      "batch: 270   d_loss:  0.047550588846206665\n",
      "batch: 270   g_loss:  2.459744453430176\n",
      "batch: 271   d_loss:  0.046984314918518066\n",
      "batch: 271   g_loss:  2.472107410430908\n",
      "batch: 272   d_loss:  0.04622381180524826\n",
      "batch: 272   g_loss:  2.4843192100524902\n",
      "batch: 273   d_loss:  0.04576191306114197\n",
      "batch: 273   g_loss:  2.496525764465332\n",
      "batch: 274   d_loss:  0.044837355613708496\n",
      "batch: 274   g_loss:  2.508679151535034\n",
      "batch: 275   d_loss:  0.044358450919389725\n",
      "batch: 275   g_loss:  2.520803928375244\n",
      "batch: 276   d_loss:  0.04428178444504738\n",
      "batch: 276   g_loss:  2.532862663269043\n",
      "batch: 277   d_loss:  0.04365061968564987\n",
      "batch: 277   g_loss:  2.5447893142700195\n",
      "batch: 278   d_loss:  0.04304879158735275\n",
      "batch: 278   g_loss:  2.55668044090271\n",
      "batch: 279   d_loss:  0.04252087324857712\n",
      "batch: 279   g_loss:  2.568613052368164\n",
      "batch: 280   d_loss:  0.04169248044490814\n",
      "batch: 280   g_loss:  2.580406665802002\n",
      "batch: 281   d_loss:  0.040934376418590546\n",
      "batch: 281   g_loss:  2.5921614170074463\n",
      "batch: 282   d_loss:  0.04239596053957939\n",
      "batch: 282   g_loss:  2.6038267612457275\n",
      "batch: 283   d_loss:  0.041508276015520096\n",
      "batch: 283   g_loss:  2.6154024600982666\n",
      "batch: 284   d_loss:  0.039980895817279816\n",
      "batch: 284   g_loss:  2.627045154571533\n",
      "batch: 285   d_loss:  0.04005603492259979\n",
      "batch: 285   g_loss:  2.6384940147399902\n",
      "batch: 286   d_loss:  0.03992718085646629\n",
      "batch: 286   g_loss:  2.649883508682251\n",
      "batch: 287   d_loss:  0.039380043745040894\n",
      "batch: 287   g_loss:  2.6612887382507324\n",
      "batch: 288   d_loss:  0.03832404688000679\n",
      "batch: 288   g_loss:  2.67264986038208\n",
      "batch: 289   d_loss:  0.03833077475428581\n",
      "batch: 289   g_loss:  2.6837759017944336\n",
      "batch: 290   d_loss:  0.0379914715886116\n",
      "batch: 290   g_loss:  2.695009231567383\n",
      "batch: 291   d_loss:  0.03731642663478851\n",
      "batch: 291   g_loss:  2.7060928344726562\n",
      "batch: 292   d_loss:  0.03652219474315643\n",
      "batch: 292   g_loss:  2.7172036170959473\n",
      "batch: 293   d_loss:  0.03602519631385803\n",
      "batch: 293   g_loss:  2.7282774448394775\n",
      "batch: 294   d_loss:  0.03588361293077469\n",
      "batch: 294   g_loss:  2.7392687797546387\n",
      "batch: 295   d_loss:  0.03565095365047455\n",
      "batch: 295   g_loss:  2.750115394592285\n",
      "batch: 296   d_loss:  0.03488538786768913\n",
      "batch: 296   g_loss:  2.761054754257202\n",
      "batch: 297   d_loss:  0.03446950018405914\n",
      "batch: 297   g_loss:  2.7718920707702637\n",
      "batch: 298   d_loss:  0.034462764859199524\n",
      "batch: 298   g_loss:  2.7826993465423584\n",
      "batch: 299   d_loss:  0.03374631702899933\n",
      "batch: 299   g_loss:  2.793365001678467\n",
      "batch: 300   d_loss:  0.033334873616695404\n",
      "batch: 300   g_loss:  2.8040528297424316\n",
      "batch: 301   d_loss:  0.03338112309575081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 301   g_loss:  2.8145852088928223\n",
      "batch: 302   d_loss:  0.03275280445814133\n",
      "batch: 302   g_loss:  2.825216770172119\n",
      "batch: 303   d_loss:  0.03256497532129288\n",
      "batch: 303   g_loss:  2.835803270339966\n",
      "batch: 304   d_loss:  0.03197375684976578\n",
      "batch: 304   g_loss:  2.84621524810791\n",
      "batch: 305   d_loss:  0.032150838524103165\n",
      "batch: 305   g_loss:  2.8566689491271973\n",
      "batch: 306   d_loss:  0.03176505118608475\n",
      "batch: 306   g_loss:  2.866934061050415\n",
      "batch: 307   d_loss:  0.03132915496826172\n",
      "batch: 307   g_loss:  2.877211093902588\n",
      "batch: 308   d_loss:  0.03120749443769455\n",
      "batch: 308   g_loss:  2.8874897956848145\n",
      "batch: 309   d_loss:  0.030762968584895134\n",
      "batch: 309   g_loss:  2.897660732269287\n",
      "batch: 310   d_loss:  0.029761793091893196\n",
      "batch: 310   g_loss:  2.9078168869018555\n",
      "batch: 311   d_loss:  0.02972453460097313\n",
      "batch: 311   g_loss:  2.9178919792175293\n",
      "batch: 312   d_loss:  0.02960982918739319\n",
      "batch: 312   g_loss:  2.928021192550659\n",
      "batch: 313   d_loss:  0.029414284974336624\n",
      "batch: 313   g_loss:  2.9378905296325684\n",
      "batch: 314   d_loss:  0.02899189479649067\n",
      "batch: 314   g_loss:  2.947787046432495\n",
      "batch: 315   d_loss:  0.02891724929213524\n",
      "batch: 315   g_loss:  2.957730293273926\n",
      "batch: 316   d_loss:  0.029238246381282806\n",
      "batch: 316   g_loss:  2.967522382736206\n",
      "batch: 317   d_loss:  0.028145279735326767\n",
      "batch: 317   g_loss:  2.977313756942749\n",
      "batch: 318   d_loss:  0.02765648439526558\n",
      "batch: 318   g_loss:  2.987041473388672\n",
      "batch: 319   d_loss:  0.027645528316497803\n",
      "batch: 319   g_loss:  2.9967355728149414\n",
      "batch: 320   d_loss:  0.027241531759500504\n",
      "batch: 320   g_loss:  3.0063388347625732\n",
      "batch: 321   d_loss:  0.02717486210167408\n",
      "batch: 321   g_loss:  3.0159554481506348\n",
      "batch: 322   d_loss:  0.02687489427626133\n",
      "batch: 322   g_loss:  3.0254509449005127\n",
      "batch: 323   d_loss:  0.027720902115106583\n",
      "batch: 323   g_loss:  3.0349037647247314\n",
      "batch: 324   d_loss:  0.026350241154432297\n",
      "batch: 324   g_loss:  3.0443344116210938\n",
      "batch: 325   d_loss:  0.02589336968958378\n",
      "batch: 325   g_loss:  3.0537118911743164\n",
      "batch: 326   d_loss:  0.02550322934985161\n",
      "batch: 326   g_loss:  3.063102960586548\n",
      "batch: 327   d_loss:  0.025943901389837265\n",
      "batch: 327   g_loss:  3.0723941326141357\n",
      "batch: 328   d_loss:  0.025732003152370453\n",
      "batch: 328   g_loss:  3.0814871788024902\n",
      "batch: 329   d_loss:  0.025142107158899307\n",
      "batch: 329   g_loss:  3.0906615257263184\n",
      "batch: 330   d_loss:  0.025091294199228287\n",
      "batch: 330   g_loss:  3.099790096282959\n",
      "batch: 331   d_loss:  0.02476668730378151\n",
      "batch: 331   g_loss:  3.1089491844177246\n",
      "batch: 332   d_loss:  0.02499460242688656\n",
      "batch: 332   g_loss:  3.117968797683716\n",
      "batch: 333   d_loss:  0.025111034512519836\n",
      "batch: 333   g_loss:  3.1269378662109375\n",
      "batch: 334   d_loss:  0.024578455835580826\n",
      "batch: 334   g_loss:  3.13581919670105\n",
      "batch: 335   d_loss:  0.023659195750951767\n",
      "batch: 335   g_loss:  3.144709587097168\n",
      "batch: 336   d_loss:  0.02334774099290371\n",
      "batch: 336   g_loss:  3.153590679168701\n",
      "batch: 337   d_loss:  0.023570697754621506\n",
      "batch: 337   g_loss:  3.162273645401001\n",
      "batch: 338   d_loss:  0.023227633908391\n",
      "batch: 338   g_loss:  3.1711983680725098\n",
      "batch: 339   d_loss:  0.02320083975791931\n",
      "batch: 339   g_loss:  3.179835796356201\n",
      "batch: 340   d_loss:  0.022770289331674576\n",
      "batch: 340   g_loss:  3.1884779930114746\n",
      "batch: 341   d_loss:  0.022526158019900322\n",
      "batch: 341   g_loss:  3.197157621383667\n",
      "batch: 342   d_loss:  0.022323714569211006\n",
      "batch: 342   g_loss:  3.2058629989624023\n",
      "batch: 343   d_loss:  0.021958857774734497\n",
      "batch: 343   g_loss:  3.2143824100494385\n",
      "batch: 344   d_loss:  0.02200615219771862\n",
      "batch: 344   g_loss:  3.2228715419769287\n",
      "batch: 345   d_loss:  0.021819844841957092\n",
      "batch: 345   g_loss:  3.231419801712036\n",
      "batch: 346   d_loss:  0.021629931405186653\n",
      "batch: 346   g_loss:  3.239773988723755\n",
      "batch: 347   d_loss:  0.021525496616959572\n",
      "batch: 347   g_loss:  3.248194456100464\n",
      "batch: 348   d_loss:  0.021280329674482346\n",
      "batch: 348   g_loss:  3.2565178871154785\n",
      "batch: 349   d_loss:  0.021096481010317802\n",
      "batch: 349   g_loss:  3.2648706436157227\n",
      "batch: 350   d_loss:  0.020957771688699722\n",
      "batch: 350   g_loss:  3.2731711864471436\n",
      "batch: 351   d_loss:  0.021024608984589577\n",
      "batch: 351   g_loss:  3.2813708782196045\n",
      "batch: 352   d_loss:  0.020834073424339294\n",
      "batch: 352   g_loss:  3.2895781993865967\n",
      "batch: 353   d_loss:  0.020794367417693138\n",
      "batch: 353   g_loss:  3.2977137565612793\n",
      "batch: 354   d_loss:  0.020363543182611465\n",
      "batch: 354   g_loss:  3.3058342933654785\n",
      "batch: 355   d_loss:  0.02010255865752697\n",
      "batch: 355   g_loss:  3.313713550567627\n",
      "batch: 356   d_loss:  0.0200534425675869\n",
      "batch: 356   g_loss:  3.32188081741333\n",
      "batch: 357   d_loss:  0.01992887258529663\n",
      "batch: 357   g_loss:  3.329922676086426\n",
      "batch: 358   d_loss:  0.019637810066342354\n",
      "batch: 358   g_loss:  3.337873935699463\n",
      "batch: 359   d_loss:  0.019142460078001022\n",
      "batch: 359   g_loss:  3.345825672149658\n",
      "batch: 360   d_loss:  0.019168276339769363\n",
      "batch: 360   g_loss:  3.3537001609802246\n",
      "batch: 361   d_loss:  0.019081097096204758\n",
      "batch: 361   g_loss:  3.3616273403167725\n",
      "batch: 362   d_loss:  0.019511792808771133\n",
      "batch: 362   g_loss:  3.369379758834839\n",
      "batch: 363   d_loss:  0.019022183492779732\n",
      "batch: 363   g_loss:  3.377218723297119\n",
      "batch: 364   d_loss:  0.019160082563757896\n",
      "batch: 364   g_loss:  3.384873390197754\n",
      "batch: 365   d_loss:  0.01905118115246296\n",
      "batch: 365   g_loss:  3.392528533935547\n",
      "batch: 366   d_loss:  0.019040284678339958\n",
      "batch: 366   g_loss:  3.4000930786132812\n",
      "batch: 367   d_loss:  0.01851421408355236\n",
      "batch: 367   g_loss:  3.407672882080078\n",
      "batch: 368   d_loss:  0.01824992522597313\n",
      "batch: 368   g_loss:  3.4152684211730957\n",
      "batch: 369   d_loss:  0.017833024263381958\n",
      "batch: 369   g_loss:  3.422785758972168\n",
      "batch: 370   d_loss:  0.01823253557085991\n",
      "batch: 370   g_loss:  3.4303159713745117\n",
      "batch: 371   d_loss:  0.018281497061252594\n",
      "batch: 371   g_loss:  3.4377174377441406\n",
      "batch: 372   d_loss:  0.018872950226068497\n",
      "batch: 372   g_loss:  3.4451112747192383\n",
      "batch: 373   d_loss:  0.01809612661600113\n",
      "batch: 373   g_loss:  3.452409029006958\n",
      "batch: 374   d_loss:  0.017574498429894447\n",
      "batch: 374   g_loss:  3.4598283767700195\n",
      "batch: 375   d_loss:  0.01797996088862419\n",
      "batch: 375   g_loss:  3.4670629501342773\n",
      "batch: 376   d_loss:  0.018053609877824783\n",
      "batch: 376   g_loss:  3.4742016792297363\n",
      "batch: 377   d_loss:  0.01799161359667778\n",
      "batch: 377   g_loss:  3.481316566467285\n",
      "batch: 378   d_loss:  0.017435425892472267\n",
      "batch: 378   g_loss:  3.488480806350708\n",
      "batch: 379   d_loss:  0.01729327253997326\n",
      "batch: 379   g_loss:  3.4955267906188965\n",
      "batch: 380   d_loss:  0.017249148339033127\n",
      "batch: 380   g_loss:  3.5025830268859863\n",
      "batch: 381   d_loss:  0.016789235174655914\n",
      "batch: 381   g_loss:  3.5096793174743652\n",
      "batch: 382   d_loss:  0.016265831887722015\n",
      "batch: 382   g_loss:  3.5166149139404297\n",
      "batch: 383   d_loss:  0.01654394343495369\n",
      "batch: 383   g_loss:  3.5236339569091797\n",
      "batch: 384   d_loss:  0.016530770808458328\n",
      "batch: 384   g_loss:  3.5306572914123535\n",
      "batch: 385   d_loss:  0.016252417117357254\n",
      "batch: 385   g_loss:  3.537618398666382\n",
      "batch: 386   d_loss:  0.016264883801341057\n",
      "batch: 386   g_loss:  3.544485092163086\n",
      "batch: 387   d_loss:  0.016142666339874268\n",
      "batch: 387   g_loss:  3.5514020919799805\n",
      "batch: 388   d_loss:  0.01589595153927803\n",
      "batch: 388   g_loss:  3.5582900047302246\n",
      "batch: 389   d_loss:  0.015713198110461235\n",
      "batch: 389   g_loss:  3.56508731842041\n",
      "batch: 390   d_loss:  0.015370212495326996\n",
      "batch: 390   g_loss:  3.5719077587127686\n",
      "batch: 391   d_loss:  0.015465064905583858\n",
      "batch: 391   g_loss:  3.5787291526794434\n",
      "batch: 392   d_loss:  0.01523115485906601\n",
      "batch: 392   g_loss:  3.5855603218078613\n",
      "batch: 393   d_loss:  0.01525772176682949\n",
      "batch: 393   g_loss:  3.5922656059265137\n",
      "batch: 394   d_loss:  0.015368546359241009\n",
      "batch: 394   g_loss:  3.5990052223205566\n",
      "batch: 395   d_loss:  0.015092277899384499\n",
      "batch: 395   g_loss:  3.605654716491699\n",
      "batch: 396   d_loss:  0.015049075707793236\n",
      "batch: 396   g_loss:  3.6123945713043213\n",
      "batch: 397   d_loss:  0.014855233952403069\n",
      "batch: 397   g_loss:  3.6188814640045166\n",
      "batch: 398   d_loss:  0.0146260354667902\n",
      "batch: 398   g_loss:  3.6255993843078613\n",
      "batch: 399   d_loss:  0.014987838454544544\n",
      "batch: 399   g_loss:  3.6322662830352783\n",
      "batch: 400   d_loss:  0.015168420039117336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 400   g_loss:  3.6386942863464355\n",
      "batch: 401   d_loss:  0.014725906774401665\n",
      "batch: 401   g_loss:  3.6452388763427734\n",
      "batch: 402   d_loss:  0.014811962842941284\n",
      "batch: 402   g_loss:  3.6516714096069336\n",
      "batch: 403   d_loss:  0.014451375231146812\n",
      "batch: 403   g_loss:  3.658155918121338\n",
      "batch: 404   d_loss:  0.014315484091639519\n",
      "batch: 404   g_loss:  3.6645870208740234\n",
      "batch: 405   d_loss:  0.014069047756493092\n",
      "batch: 405   g_loss:  3.670893430709839\n",
      "batch: 406   d_loss:  0.013961468823254108\n",
      "batch: 406   g_loss:  3.677386999130249\n",
      "batch: 407   d_loss:  0.013908563181757927\n",
      "batch: 407   g_loss:  3.6838302612304688\n",
      "batch: 408   d_loss:  0.013805081136524677\n",
      "batch: 408   g_loss:  3.6901538372039795\n",
      "batch: 409   d_loss:  0.014260204508900642\n",
      "batch: 409   g_loss:  3.6964333057403564\n",
      "batch: 410   d_loss:  0.013815373182296753\n",
      "batch: 410   g_loss:  3.7027347087860107\n",
      "batch: 411   d_loss:  0.013575704768300056\n",
      "batch: 411   g_loss:  3.708984851837158\n",
      "batch: 412   d_loss:  0.013633981347084045\n",
      "batch: 412   g_loss:  3.7151939868927\n",
      "batch: 413   d_loss:  0.013541501946747303\n",
      "batch: 413   g_loss:  3.721322536468506\n",
      "batch: 414   d_loss:  0.013945517130196095\n",
      "batch: 414   g_loss:  3.7275304794311523\n",
      "batch: 415   d_loss:  0.013322524726390839\n",
      "batch: 415   g_loss:  3.7336854934692383\n",
      "batch: 416   d_loss:  0.013279339298605919\n",
      "batch: 416   g_loss:  3.7397918701171875\n",
      "batch: 417   d_loss:  0.013163307681679726\n",
      "batch: 417   g_loss:  3.7458572387695312\n",
      "batch: 418   d_loss:  0.01293942891061306\n",
      "batch: 418   g_loss:  3.7519373893737793\n",
      "batch: 419   d_loss:  0.012936725281178951\n",
      "batch: 419   g_loss:  3.758026599884033\n",
      "batch: 420   d_loss:  0.012799748219549656\n",
      "batch: 420   g_loss:  3.7641196250915527\n",
      "batch: 421   d_loss:  0.013209913857281208\n",
      "batch: 421   g_loss:  3.770080089569092\n",
      "batch: 422   d_loss:  0.012988036498427391\n",
      "batch: 422   g_loss:  3.776089668273926\n",
      "batch: 423   d_loss:  0.012568277306854725\n",
      "batch: 423   g_loss:  3.781980514526367\n",
      "batch: 424   d_loss:  0.0130161689594388\n",
      "batch: 424   g_loss:  3.7879629135131836\n",
      "batch: 425   d_loss:  0.012843823991715908\n",
      "batch: 425   g_loss:  3.793853998184204\n",
      "batch: 426   d_loss:  0.012734378688037395\n",
      "batch: 426   g_loss:  3.799699306488037\n",
      "batch: 427   d_loss:  0.01256648264825344\n",
      "batch: 427   g_loss:  3.8055310249328613\n",
      "batch: 428   d_loss:  0.012437408789992332\n",
      "batch: 428   g_loss:  3.81132173538208\n",
      "batch: 429   d_loss:  0.012617362663149834\n",
      "batch: 429   g_loss:  3.817203998565674\n",
      "batch: 430   d_loss:  0.01248567271977663\n",
      "batch: 430   g_loss:  3.822911024093628\n",
      "batch: 431   d_loss:  0.012431586161255836\n",
      "batch: 431   g_loss:  3.828603506088257\n",
      "batch: 432   d_loss:  0.011948497965931892\n",
      "batch: 432   g_loss:  3.8344573974609375\n",
      "batch: 433   d_loss:  0.012174632400274277\n",
      "batch: 433   g_loss:  3.8400275707244873\n",
      "batch: 434   d_loss:  0.012685773894190788\n",
      "batch: 434   g_loss:  3.8457140922546387\n",
      "batch: 435   d_loss:  0.012543555349111557\n",
      "batch: 435   g_loss:  3.851344108581543\n",
      "batch: 436   d_loss:  0.011838270351290703\n",
      "batch: 436   g_loss:  3.856933832168579\n",
      "batch: 437   d_loss:  0.011982966214418411\n",
      "batch: 437   g_loss:  3.8624563217163086\n",
      "batch: 438   d_loss:  0.012005532160401344\n",
      "batch: 438   g_loss:  3.868077278137207\n",
      "batch: 439   d_loss:  0.01166593935340643\n",
      "batch: 439   g_loss:  3.873683452606201\n",
      "batch: 440   d_loss:  0.011322657577693462\n",
      "batch: 440   g_loss:  3.8791637420654297\n",
      "batch: 441   d_loss:  0.011647539213299751\n",
      "batch: 441   g_loss:  3.884716272354126\n",
      "batch: 442   d_loss:  0.011635344475507736\n",
      "batch: 442   g_loss:  3.8902111053466797\n",
      "batch: 443   d_loss:  0.011848174035549164\n",
      "batch: 443   g_loss:  3.8956356048583984\n",
      "batch: 444   d_loss:  0.011395192705094814\n",
      "batch: 444   g_loss:  3.901162624359131\n",
      "batch: 445   d_loss:  0.011149417608976364\n",
      "batch: 445   g_loss:  3.9065518379211426\n",
      "batch: 446   d_loss:  0.01120010670274496\n",
      "batch: 446   g_loss:  3.9120590686798096\n",
      "batch: 447   d_loss:  0.011190827935934067\n",
      "batch: 447   g_loss:  3.9173614978790283\n",
      "batch: 448   d_loss:  0.011188911274075508\n",
      "batch: 448   g_loss:  3.9228157997131348\n",
      "batch: 449   d_loss:  0.011113932356238365\n",
      "batch: 449   g_loss:  3.9281280040740967\n",
      "batch: 450   d_loss:  0.010858604684472084\n",
      "batch: 450   g_loss:  3.933434009552002\n",
      "batch: 451   d_loss:  0.010671143420040607\n",
      "batch: 451   g_loss:  3.938856601715088\n",
      "batch: 452   d_loss:  0.010809455066919327\n",
      "batch: 452   g_loss:  3.944242477416992\n",
      "batch: 453   d_loss:  0.010826464742422104\n",
      "batch: 453   g_loss:  3.949493646621704\n",
      "batch: 454   d_loss:  0.010692460462450981\n",
      "batch: 454   g_loss:  3.954894542694092\n",
      "batch: 455   d_loss:  0.010756983421742916\n",
      "batch: 455   g_loss:  3.9599766731262207\n",
      "batch: 456   d_loss:  0.011119849979877472\n",
      "batch: 456   g_loss:  3.965336799621582\n",
      "batch: 457   d_loss:  0.010286600328981876\n",
      "batch: 457   g_loss:  3.970560073852539\n",
      "batch: 458   d_loss:  0.01004473865032196\n",
      "batch: 458   g_loss:  3.975748062133789\n",
      "batch: 459   d_loss:  0.010459888726472855\n",
      "batch: 459   g_loss:  3.9809908866882324\n",
      "batch: 460   d_loss:  0.010495202615857124\n",
      "batch: 460   g_loss:  3.9861934185028076\n",
      "batch: 461   d_loss:  0.010228006169199944\n",
      "batch: 461   g_loss:  3.991394519805908\n",
      "batch: 462   d_loss:  0.010249418206512928\n",
      "batch: 462   g_loss:  3.9965031147003174\n",
      "batch: 463   d_loss:  0.012235386297106743\n",
      "batch: 463   g_loss:  4.001477241516113\n",
      "batch: 464   d_loss:  0.014085473492741585\n",
      "batch: 464   g_loss:  4.006340980529785\n",
      "batch: 465   d_loss:  0.009979570284485817\n",
      "batch: 465   g_loss:  4.011221885681152\n",
      "batch: 466   d_loss:  0.010224753990769386\n",
      "batch: 466   g_loss:  4.016077518463135\n",
      "batch: 467   d_loss:  0.010244018398225307\n",
      "batch: 467   g_loss:  4.0209503173828125\n",
      "Epoch #:  1\n",
      "Number of batches 468\n",
      "batch: 0   d_loss:  0.010187388397753239\n",
      "batch: 0   g_loss:  4.025854587554932\n",
      "batch: 1   d_loss:  0.009920628741383553\n",
      "batch: 1   g_loss:  4.030837059020996\n",
      "batch: 2   d_loss:  0.009863315150141716\n",
      "batch: 2   g_loss:  4.035701274871826\n",
      "batch: 3   d_loss:  0.0099688321352005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-d277f3319df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-31704a6e5729>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_with_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch: {}   g_loss:  {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    949\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    950\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelkane/anaconda3/envs/MS-ML-P3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:MS-ML-P3]",
   "language": "python",
   "name": "conda-env-MS-ML-P3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
